server:
  port: 8080
  loglevel: "DEBUG"

  protocol: "https"
  ## API basepath. Must match an ingress in the ingress.basepaths list.
  apiBasePath: "api/v1"
  basePath: ""
  ## API hostname. Must match the ingress.hostname value.
  hostName: "mmli.fastapi.mmli1.ncsa.illinois.edu"

minio:
  server: "minio:9000"
  apiBaseUrl: "minioapi.mmli.fastapi.localhost"

auth:
  userInfoUrl: "http://oauth2.proxy.local/oauth2/userinfo"
  cookiename: "_oauth2_proxy"

email:
  server: "smtp.ncsa.uiuc.edu"
  fromEmail: "devnull+alphasynthesis@ncsa.illinois.edu"
  fromName: "no-reply-ALPHASYNTHESIS"

kubernetes_jobs:
  # Config for running CLEAN job
  clean:
    image: "moleculemaker/clean-image-amd64:latest"
    imagePullPolicy: "Always"
    volumes:
      # TODO: Refactor volumes in CLEAN
      - name: 'shared-storage'
        mountPath: '/app/data/inputs'
        subPath: 'uws/jobs/clean/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/app/results/inputs'
        subPath: 'output'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/root/.cache/torch/hub/checkpoints'
        subPath: 'weights'
        claimName: 'mmli-clean-job-weights'


  # Config for running MOLLI job
  molli:
    image: "moleculemaker/molli:ncsa-workflow"
    command: "/molli/entrypoint.sh"
    imagePullPolicy: "Always"
    imagePullSecrets:
      - regcred
    volumes:
      # TODO: Refactor volumes in MOLLI
      - name: 'shared-storage'
        mountPath: '/app/data/inputs'
        subPath: 'input'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/app/results/inputs'
        subPath: 'output'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/root/.cache/torch/hub/checkpoints'
        subPath: 'weights'
        claimName: 'mmli-clean-job-weights'

  # Config for running SOMN job
  somn:
    image: "bodom0015/somn"
    imagePullPolicy: "Always"

  # Config for running NovoStoic job (subjob: OptStoic)
  novostoic_optstoic:
    image: "TBD"
    imagePullPolicy: "Always"

  defaults:
    # Kubeconfig (credentials + cluster) used to run this job in Kubernetes
    kubeconfig: "/opt/kubeconfig"
    # Namespace where this job should run
    namespace: "mmli"

    # Example job image name + command combo
    image: 'perl:5.34.0'
    command: "perl -Mbignum=bpi -wle 'print bpi(2000)' > ${JOB_OUTPUT_DIR}/pi.out"

    ## Server working directory to store generated job data
    workingVolume:
      claimName: "mmli-clean-job-weights"
      mountPath: "/uws"
      subPath: "uws"
    ## Central data volumes to be mounted in job containers
    volumes:
      - name: 'shared-storage'
        mountPath: '/app/data/inputs'
        subPath: 'input'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/app/results/inputs'
        subPath: 'output'
        claimName: 'mmli-clean-job-weights'

    ## Abort jobs after 3 days regardless of their behavior
    activeDeadlineSeconds: 259200
    ## Cleanup completed/failed jobs after 12 hours
    ttlSecondsAfterFinished: 43200
    ## Poll the log file for changes every `logFilePollingPeriod` seconds
    logFilePollingPeriod: 300
    securityContext:
      runAsUser: 0
      runAsGroup: 0
      # fsGroup: 202

    # TODO: probably could adjust resource limits here
    resources:
      limits:
        cpu: "1"
        memory: "16Gi"
      requests:
        cpu: "1"
        memory: "12Gi"

external:
  chemscraper:
      apiBaseUrl: "https://chemscraper.backend.staging.mmli1.ncsa.illinois.edu"
      frontendBaseUrl: "https://chemscraper.frontend.staging.mmli1.ncsa.illinois.edu"


