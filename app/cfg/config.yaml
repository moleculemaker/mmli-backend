server:
  port: 8080
  loglevel: "DEBUG"

  protocol: "https"
  ## API basepath. Must match an ingress in the ingress.basepaths list.
  apiBasePath: "api/v1"
  basePath: ""
  ## API hostname. Must match the ingress.hostname value.
  hostName: "mmli.fastapi.mmli1.ncsa.illinois.edu"

minio:
  server: "minio:9000"
  apiBaseUrl: "minioapi.mmli.fastapi.localhost"

auth:
  userInfoUrl: "https://auth.platform.moleculemaker.org/oauth2/userinfo"
  cookiename: "_oauth2_proxy"

email:
  server: "smtp.ncsa.uiuc.edu"
  fromEmail: "devnull+alphasynthesis@ncsa.illinois.edu"
  fromName: "no-reply-ALPHASYNTHESIS"

# Change frontend service URLs depending on where they're deployed (used for email notifications)
chemscraper_url: "http://chemscraper-services-staging.staging.svc.cluster.local:8000"
chemscraper_frontend_url: "https://chemscraper.frontend.staging.mmli1.ncsa.illinois.edu"
novostoic_frontend_url: "https://novostoic.frontend.staging.mmli1.ncsa.illinois.edu"
somn_frontend_url: "https://somn.frontend.staging.mmli1.ncsa.illinois.edu"
clean_frontend_url: "https://clean.frontend.staging.mmli1.ncsa.illinois.edu"
molli_frontend_url: "https://molli.frontend.staging.mmli1.ncsa.illinois.edu"
aceretro_frontend_url: "https://aceretro.frontend.staging.mmli1.ncsa.illinois.edu"
openenzymedb_frontend_url: "https://frontend.staging.openenzymedb.mmli1.ncsa.illinois.edu"

kubernetes_jobs:
  aceretro:
    image: "kastanday/aceretro:slimer"
    imagePullPolicy: "Always"
    # command: "python entrypoint.py" # defined in job.py
    volumes:
    - name: 'shared-storage'
      mountPath: '/uws/jobs/aceretro/JOB_ID/in'
      subPath: 'uws/jobs/aceretro/JOB_ID/in'
      claimName: 'mmli-clean-job-weights'
    - name: 'shared-storage'
      mountPath: '/uws/jobs/aceretro/JOB_ID/out'
      subPath: 'uws/jobs/aceretro/JOB_ID/out'
      claimName: 'mmli-clean-job-weights'
    # env:
    #   - name: MINIO_ACCESS_KEY
    #     valueFrom:
    #       secretKeyRef:
    #         name: mmli-backend-minio
    #         key: root-password
    #   - name: MINIO_SECRET_ACCESS_KEY
    #     valueFrom:
    #       secretKeyRef:
    #         name: mmli-backend-minio
    #         key: root-user
    #   - name: MINIO_URL
    #     value: "minioapi.mmli.fastapi.staging.mmli1.ncsa.illinois.edu"
    resources:
      limits:
        cpu: "4"
        memory: 24Gi
      requests:
        cpu: "2"
        memory: 12Gi
  
  # Config for running CLEAN job
  clean:
    image: "moleculemaker/clean-image-amd64:latest"
    imagePullPolicy: "Always"
    volumes:
      # TODO: Refactor volumes in CLEAN
      - name: 'shared-storage'
        mountPath: '/app/data/inputs'
        subPath: 'uws/jobs/clean/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/app/results/inputs'
        subPath: 'output'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/root/.cache/torch/hub/checkpoints'
        subPath: 'weights'
        claimName: 'mmli-clean-job-weights'


  # Config for running MOLLI job
  molli:
    image: "ghcr.io/moleculemaker/molli:ncsa-workflow"
    command: "/molli/entrypoint.sh"
    imagePullPolicy: "Always"
    imagePullSecrets:
      - regcred
    volumes:
      # TODO: Refactor volumes in MOLLI
      - name: 'shared-storage'
        mountPath: '/app/data/inputs'
        subPath: 'input'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/app/results/inputs'
        subPath: 'output'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/root/.cache/torch/hub/checkpoints'
        subPath: 'weights'
        claimName: 'mmli-clean-job-weights'

  # Config for running OpenEnzymeDB job(s)
  oed-dlkcat:
    image: 'moleculemaker/oed-dlkcat-dla'
    imagePullPolicy: 'Always'
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/oed-dlkcat/JOB_ID/in'
        subPath: 'uws/jobs/oed-dlkcat/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/uws/jobs/oed-dlkcat/JOB_ID/out'
        subPath: 'uws/jobs/oed-dlkcat/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'
  oed-unikp:
    image: 'moleculemaker/oed-unikp'
    imagePullPolicy: 'Always'
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/oed-unikp/JOB_ID/in'
        subPath: 'uws/jobs/oed-unikp/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/uws/jobs/oed-unikp/JOB_ID/out'
        subPath: 'uws/jobs/oed-unikp/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'
      - mountPath: /root/.cache/huggingface/hub
        name: shared-storage
        subPath: uws/jobs/oed-unikp/.cache
        claimName: 'mmli-clean-job-weights'
      - mountPath: /usr/app/UniKP
        name: shared-storage
        subPath: uws/jobs/oed-unikp/.models
        claimName: 'mmli-clean-job-weights'
    secrets:
      - mountPath: '/root/.cache/token'
        name: 'token'
        subPath: 'token'
        readOnly: 'true'
        secretName: huggingface-token
        # "itemList" takes the place of "items"
        # This should avoid overlap with the built-in items() function
        itemList:
          - key: token
            path: token
  oed-catpred:
    image: 'moleculemaker/oed-catpred'
    imagePullPolicy: 'Always'
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/oed-catpred/JOB_ID/in'
        subPath: 'uws/jobs/oed-catpred/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/uws/jobs/oed-catpred/JOB_ID/out'
        subPath: 'uws/jobs/oed-catpred/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'
      - mountPath: /data
        name: shared-storage
        subPath: uws/jobs/oed-unikp/.pretrained
        claimName: 'mmli-clean-job-weights'

  # Config for running ReactionMiner job
  reactionminer:
    image: "moleculemaker/reactionminer:latest"
    imagePullPolicy: "Always"
    env:
    - name: HF_TOKEN_PATH
      value: '/root/.cache/token'
    - name: GROBID_SERVER
      value: 'localhost'
    volumes:
      - name: 'shared-storage'
        mountPath: '/workspace/10test/'
        subPath: 'uws/jobs/reactionminer/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/workspace/extraction/results_filtered/'
        subPath: 'uws/jobs/reactionminer/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'
      - mountPath: '/root/.cache/huggingface/hub'
        name: 'shared-storage'
        subPath: 'uws/jobs/reactionminer/.cache'
        claimName: 'mmli-clean-job-weights'

    # Create a secret named HuggingFace API token
    # Format:
    #   apiVersion: v1
    #   kind: Secret
    #   data:
    #     token: YOUR_API_TOKEN
    secrets:
      - mountPath: '/root/.cache/token'
        name: 'token'
        subPath: 'token'
        readOnly: 'true'
        secretName: huggingface-token
        # "itemList" takes the place of "items"
        # This should avoid overlap with the built-in items() function
        itemList:
          - key: token
            path: token

  # Config for running SOMN job
  somn:
    image: "ianrinehart/somn:1.2.1"
    command: "cp ${JOB_INPUT_DIR}/example_request.csv ${SOMN_PROJECT_DIR}/scratch/test_request.csv && micromamba run -n base somn predict last latest asdf && cp -r ${SOMN_PROJECT_DIR}/outputs/asdf/*/* ${JOB_OUTPUT_DIR}"
    projectDirectory: '/tmp/somn_root/somn_scratch/IID-Models-2024'
    imagePullPolicy: "Always"
    securityContext:
      # TODO: mount/run as mambauser => 57439 causes permission errors
      # workaround for now is to run as root
      runAsUser: 0
      runAsGroup: 0
      #fsGroup: 57439
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/somn/JOB_ID/in'
        subPath: 'uws/jobs/somn/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/uws/jobs/somn/JOB_ID/out'
        subPath: 'uws/jobs/somn/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'

  # Config for running NovoStoic job (subjob: OptStoic)
  novostoic-optstoic:
    image: "moleculemaker/novostoic"
    command: "python ./novostoic-job.py optstoic"
    imagePullPolicy: "Always"
    #imagePullSecrets:
    #  - regcred
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/novostoic-optstoic/JOB_ID/out'
        subPath: 'uws/jobs/novostoic-optstoic/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'

  # Config for running NovoStoic job (subjob: NovoStoic Pathways Search)
  novostoic-pathways:
    image: "moleculemaker/novostoic"
    command: "python ./novostoic-job.py pathways"
    imagePullPolicy: "Always"
    #imagePullSecrets:
    #  - regcred
    volumes:
      - name: 'shared-storage'
        mountPath: 'uws/jobs/novostoic-pathways/JOB_ID/out'
        subPath: 'uws/jobs/novostoic-pathways/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'

  # Config for running NovoStoic job (subjob: dGPredictor)
  novostoic-dgpredictor:
    image: "moleculemaker/novostoic"
    command: "python ./novostoic-job.py dgpredictor"
    imagePullPolicy: "Always"
    #imagePullSecrets:
    #  - regcred
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/novostoic-dgpredictor/JOB_ID/out'
        subPath: 'uws/jobs/novostoic-dgpredictor/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'

  # Config for running NovoStoic job (subjob: EnzRank)
  novostoic-enzrank:
    image: "moleculemaker/novostoic"
    command: "python ./novostoic-job.py enzrank"
    imagePullPolicy: "Always"
    #imagePullSecrets:
    #  - regcred
    volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/novostoic-enzrank/JOB_ID/out'
        subPath: 'uws/jobs/novostoic-enzrank/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'

  defaults:
    # Kubeconfig (credentials + cluster) used to run this job in Kubernetes
    kubeconfig: "/opt/kubeconfig"
    # Namespace where this job should run
    namespace: "mmli"

    # Example job image name + command combo
    image: 'perl:5.34.0'
    command: "perl -Mbignum=bpi -wle 'print bpi(2000)' > ${JOB_OUTPUT_DIR}/pi.out"

    ## Server working directory to store generated job data
    workingVolume:
      claimName: "mmli-clean-job-weights"
      mountPath: "/uws"
      subPath: "uws"
    ## Central data volumes to be mounted in job containers
    volumes: []

    ## Abort jobs after 3 days regardless of their behavior
    activeDeadlineSeconds: 259200
    ## Cleanup completed/failed jobs after 12 hours
    ttlSecondsAfterFinished: 43200
    ## Poll the log file for changes every `logFilePollingPeriod` seconds
    logFilePollingPeriod: 300
    securityContext:
      runAsUser: 0
      runAsGroup: 0
      # fsGroup: 202

    # TODO: probably could adjust resource limits here
    resources:
      limits:
        cpu: "64"
        memory: "24Gi"
      requests:
        cpu: "16"
        memory: "12Gi"

external:
  chemscraper:
      apiBaseUrl: "https://chemscraper.backend.staging.mmli1.ncsa.illinois.edu"
      frontendBaseUrl: "https://chemscraper.frontend.staging.mmli1.ncsa.illinois.edu"


