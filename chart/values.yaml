# General ingress for all endpoints (except /chemscraper/analyze)
ingress:
  hostname: mmli.fastapi.localhost
  tls: false
  annotations: {}

# Custom ingress configuration for only /chemscraper/analyze endpoint
analyzeIngress:
  hostname: mmli.fastapi.localhost
  tls: false
  annotations: {}


controller:
  image: moleculemaker/mmli-backend:latest

sharedStorage:
  existingClaim: mmli-clean-job-weights
  mountPath: /uws
  subPath: uws

# https://artifacthub.io/packages/helm/bitnami/postgresql?modal=values
postgresql:
  enabled: true
  hostname: ""
  auth:
    # Use an existing secret - this overrides username, password, and rootPassword
    # existingSecret: ""

    # Local development only - hardcode credentials here for simplicity
    # rootPassword: ""
    # password: ""

    # Set the name of your postgresql user
    username: "postgres"

    # Set the name of your postgresql database
    database: "mmli"

# https://artifacthub.io/packages/helm/bitnami/minio?modal=values
minio:
  enabled: true
  apiIngress:
    enabled: true
    tls: false
    hostname: minioapi.mmli.fastapi.localhost
    annotations: {}
  ingress:
    enabled: true
    tls: false
    hostname: minio.mmli.fastapi.localhost 
    annotations: {}
  auth:
    # Use an existing secret - this overrides username, password, and rootPassword
    # existingSecret: ""

    # Local development only - hardcode credentials here for simplicity
    # rootUser: "admin"
    # rootPassword: ""


config:
  server:
    port: 8080
    loglevel: "DEBUG"

    protocol: "https"
    ## API basepath. Must match an ingress in the ingress.basepaths list.
    apiBasePath: "api/v1"
    basePath: ""
    ## API hostname. Must match the ingress.hostname value.
    hostName: "mmli.fastapi.mmli1.ncsa.illinois.edu"

  db:
    url: ''
    
  minio:
    server: "mmli-backend-minio.mmli.svc.cluster.local:9000"
    apiBaseUrl: "minioapi.mmli.fastapi.localhost"
    accessKey: ''
    secretKey: ''

  auth:
    userInfoUrl: "http://oauth2.proxy.local/oauth2/userinfo"
    cookiename: "_oauth2_proxy"

  email:
    server: "smtp.ncsa.uiuc.edu"
    fromEmail: "devnull+alphasynthesis@ncsa.illinois.edu"
    fromName: "no-reply-ALPHASYNTHESIS"

  kubernetes_jobs:
    # Config for running CLEAN job
    clean:
      image: "moleculemaker/clean-image-amd64:latest"
      imagePullPolicy: "Always"
      volumes:
        # TODO: Refactor volumes in CLEAN
        - name: 'shared-storage'
          mountPath: '/app/data/inputs'
          subPath: 'uws/jobs/clean/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/app/results/inputs'
          subPath: 'output'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/root/.cache/torch/hub/checkpoints'
          subPath: 'weights'
          claimName: 'mmli-clean-job-weights'


    # Config for running MOLLI job
    molli:
      image: "ghcr.io/moleculemaker/molli:ncsa-workflow"
      command: "/molli/entrypoint.sh"
      imagePullPolicy: "Always"
      imagePullSecrets:
        - regcred
      volumes:
        # TODO: Refactor volumes in MOLLI
        - name: 'shared-storage'
          mountPath: '/uws/jobs/clean/JOB_ID/in'
          subPath: 'uws/jobs/clean/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/app/results/inputs'
          subPath: 'output'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/root/.cache/torch/hub/checkpoints'
          subPath: 'weights'
          claimName: 'mmli-clean-job-weights'

    # Config for running SOMN job
    somn:
      image: "bodom0015/somn"
      imagePullPolicy: "Always"

    # Config for running NovoStoic job (subjob: OptStoic)
    novostoic_optstoic:
      image: "TBD"
      imagePullPolicy: "Always"

    defaults:
      # Kubeconfig (credentials + cluster) used to run this job in Kubernetes
      kubeconfig: "/opt/kubeconfig"
      # Namespace where this job should run
      namespace: "mmli"

      # Example job image name + command combo
      image: 'perl:5.34.0'
      command: "perl -Mbignum=bpi -wle 'print bpi(2000)' > ${JOB_OUTPUT_DIR}/pi.out"

      ## Server working directory to store generated job data
      workingVolume:
        claimName: "mmli-clean-job-weights"
        mountPath: "/uws"
        subPath: "uws"
      ## Central data volumes to be mounted in job containers
      volumes: []

      ## Abort jobs after 3 days regardless of their behavior
      activeDeadlineSeconds: 259200
      ## Cleanup completed/failed jobs after 12 hours
      ttlSecondsAfterFinished: 43200
      ## Poll the log file for changes every `logFilePollingPeriod` seconds
      logFilePollingPeriod: 300
      securityContext:
        runAsUser: 0
        runAsGroup: 0
        # fsGroup: 202

      # TODO: probably could adjust resource limits here
      resources:
        limits:
          cpu: "1"
          memory: "16Gi"
        requests:
          cpu: "1"
          memory: "12Gi"

  external:
    chemscraper:
      apiBaseUrl: "https://chemscraper.backend.staging.mmli1.ncsa.illinois.edu"
      frontendBaseUrl: "https://chemscraper.frontend.staging.mmli1.ncsa.illinois.edu"


