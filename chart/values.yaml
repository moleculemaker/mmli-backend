# General ingress for all endpoints (except /chemscraper/analyze)
ingress:
  hostname: mmli.fastapi.localhost
  tls: false
  annotations: {}

# Custom ingress configuration for only /chemscraper/analyze endpoint
analyzeIngress:
  hostname: mmli.fastapi.localhost
  tls: false
  annotations: {}


controller:
  image: moleculemaker/mmli-backend:latest

sharedStorage:
  existingClaim: mmli-clean-job-weights
  mountPath: /uws
  subPath: uws

# https://artifacthub.io/packages/helm/bitnami/postgresql?modal=values
postgresql:
  enabled: true
  autoschema: false
  hostname: ""
  auth:
    # Use an existing secret - this overrides username, password, and rootPassword
    # existingSecret: ""

    # Local development only - hardcode credentials here for simplicity
    # rootPassword: ""
    # password: ""

    # Set the name of your postgresql user
    username: "postgres"

    # Set the name of your postgresql database
    database: "mmli"

# https://artifacthub.io/packages/helm/bitnami/minio?modal=values
minio:
  enabled: true
  apiIngress:
    enabled: true
    tls: false
    hostname: minioapi.mmli.fastapi.localhost
    annotations: {}
  ingress:
    enabled: true
    tls: false
    hostname: minio.mmli.fastapi.localhost 
    annotations: {}
  auth:
    # Use an existing secret - this overrides username, password, and rootPassword
    # existingSecret: ""

    # Local development only - hardcode credentials here for simplicity
    # rootUser: "admin"
    # rootPassword: ""


config:
  # Change frontend service URLs depending on where they're deployed (used for email notifications)
  # TODO: Default these to local cluster? For now, default is staging and we override for prod
  chemscraper_url: "http://chemscraper-services-staging.staging.svc.cluster.local:8000"
  chemscraper_frontend_url: "https://chemscraper.frontend.staging.mmli1.ncsa.illinois.edu"
  novostoic_frontend_url: "https://novostoic.frontend.staging.mmli1.ncsa.illinois.edu"
  somn_frontend_url: "https://somn.frontend.staging.mmli1.ncsa.illinois.edu"
  clean_frontend_url: "https://clean.frontend.staging.mmli1.ncsa.illinois.edu"
  molli_frontend_url: "https://molli.frontend.staging.mmli1.ncsa.illinois.edu"
  aceretro_frontend_url: "https://aceretro.frontend.staging.mmli1.ncsa.illinois.edu"
  openenzymedb_frontend_url: "https://frontend.staging.openenzymedb.mmli1.ncsa.illinois.edu"

  server:
    port: 8080
    loglevel: "DEBUG"

    protocol: "https"
    ## API basepath. Must match an ingress in the ingress.basepaths list.
    apiBasePath: "api/v1"
    basePath: ""
    ## API hostname. Must match the ingress.hostname value.
    hostName: "mmli.fastapi.mmli1.ncsa.illinois.edu"

  db:
    url: ''

  minio:
    server: "mmli-backend-minio.mmli.svc.cluster.local:9000"
    apiBaseUrl: "minioapi.mmli.fastapi.localhost"
    accessKey: ''
    secretKey: ''

  auth:
    userInfoUrl: "http://oauth2.proxy.local/oauth2/userinfo"
    cookiename: "_oauth2_proxy"

  email:
    server: "smtp.ncsa.uiuc.edu"
    fromEmail: "devnull+alphasynthesis@ncsa.illinois.edu"
    fromName: "no-reply-ALPHASYNTHESIS"

  kubernetes_jobs:
    # ACERetro backend
    # Example usage:
    # curl -X POST https://mmli.kastan.ai/aceretro/jobs \
    #   -H "Content-Type: application/json" \
    #   -d '{
    #     "job_id": "123",
    #     "email": "user@gmail.com",
    #     "job_info": "{\"smiles\": \"O=C(COP(=O)(O)O)[C@H](O)[C@H](O)CO\"}"
    #   }'
    aceretro:
      image: "kastanday/aceretro:slimer"
      imagePullPolicy: "Always"
      # command: "python entrypoint.py" # defined in job.py
      volumes:
      - name: 'shared-storage'
        mountPath: '/uws/jobs/aceretro/JOB_ID/in'
        subPath: 'uws/jobs/aceretro/JOB_ID/in'
        claimName: 'mmli-clean-job-weights'
      - name: 'shared-storage'
        mountPath: '/uws/jobs/aceretro/JOB_ID/out'
        subPath: 'uws/jobs/aceretro/JOB_ID/out'
        claimName: 'mmli-clean-job-weights'
      resources:
        limits:
          cpu: "4"
          memory: 24Gi
        requests:
          cpu: "2"
          memory: 12Gi

    # Config for running CLEAN job
    clean:
      image: "moleculemaker/clean-image-amd64:latest"
      imagePullPolicy: "Always"
      volumes:
        # TODO: Refactor volumes in CLEAN
        - name: 'shared-storage'
          mountPath: '/app/data/inputs'
          subPath: 'uws/jobs/clean/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/app/results/inputs'
          subPath: 'output'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/root/.cache/torch/hub/checkpoints'
          subPath: 'weights'
          claimName: 'mmli-clean-job-weights'


    # Config for running MOLLI job
    molli:
      image: "ghcr.io/moleculemaker/molli:ncsa-workflow"
      command: "/molli/entrypoint.sh"
      imagePullPolicy: "Always"
      imagePullSecrets:
        - regcred
      volumes:
        # TODO: Refactor volumes in MOLLI
        - name: 'shared-storage'
          mountPath: '/uws/jobs/clean/JOB_ID/in'
          subPath: 'uws/jobs/clean/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/app/results/inputs'
          subPath: 'output'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/root/.cache/torch/hub/checkpoints'
          subPath: 'weights'
          claimName: 'mmli-clean-job-weights'


    # Config for running OpenEnzymeDB DLKcat job
    oed-dlkcat:
      image: 'moleculemaker/oed-dlkcat-dla'
      imagePullPolicy: 'Always'
      volumes:
        - name: 'shared-storage'
          mountPath: '/uws/jobs/oed-dlkcat/JOB_ID/in'
          subPath: 'uws/jobs/oed-dlkcat/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/uws/jobs/oed-dlkcat/JOB_ID/out'
          subPath: 'uws/jobs/oed-dlkcat/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'

    # Config for running OpenEnzymeDB UniKP job
    oed-unikp:
      image: 'moleculemaker/oed-unikp'
      imagePullPolicy: 'Always'
      volumes:
        - mountPath: /root/.cache/huggingface/hub
          name: shared-storage
          subPath: uws/jobs/oed-unikp/.cache
          claimName: 'mmli-clean-job-weights'
        - mountPath: /usr/app/UniKP
          name: shared-storage
          subPath: uws/jobs/oed-unikp/.models
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/uws/jobs/oed-unikp/JOB_ID/in'
          subPath: 'uws/jobs/oed-unikp/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/uws/jobs/oed-unikp/JOB_ID/out'
          subPath: 'uws/jobs/oed-unikp/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'
      secrets:
        - mountPath: '/root/.cache/token'
          name: 'token'
          subPath: 'token'
          readOnly: 'true'
          secretName: huggingface-token
          # "itemList" takes the place of "items"
          # This should avoid overlap with the built-in items() function
          itemList:
            - key: token
              path: token


    # Config for running OpenEnzymeDB CatPred job
    oed-catpred:
      image: 'moleculemaker/oed-catpred'
      imagePullPolicy: 'Always'
      volumes:
        - name: 'shared-storage'
          mountPath: '/uws/jobs/oed-catpred/JOB_ID/in'
          subPath: 'uws/jobs/oed-catpred/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/uws/jobs/oed-catpred/JOB_ID/out'
          subPath: 'uws/jobs/oed-catpred/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'
        - mountPath: /catpred_pipeline/data
          name: shared-storage
          subPath: uws/jobs/oed-catpred/.pretrained
          claimName: 'mmli-clean-job-weights'
        - mountPath: /catpred_pipeline/catpred/production_models
          name: shared-storage
          subPath: uws/jobs/oed-catpred/.pretrained/pretrained/production
          claimName: 'mmli-clean-job-weights'

    # Config for running ReactionMiner job
    reactionminer:
      image: "moleculemaker/reactionminer:ReactionMiner_v2"
      imagePullPolicy: "Always"
      env:
      - name: HF_TOKEN_PATH
        value: '/root/.cache/token'
      - name: GROBID_SERVER
        value: 'mmli-grobid-staging.staging.svc.cluster.local'
      - name: CHEMSCRAPER_BASE_URL	
        value: "http://chemscraper-services-staging.staging.svc.cluster.local:8000"	
      volumes:
        - name: 'shared-storage'
          mountPath: '/workspace/10test/'
          subPath: 'uws/jobs/reactionminer/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/workspace/extraction/results_filtered/'
          subPath: 'uws/jobs/reactionminer/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'
        - mountPath: '/root/.cache/huggingface/hub'
          name: 'shared-storage'
          subPath: 'uws/jobs/reactionminer/.cache'
          claimName: 'mmli-clean-job-weights'

      # Create a secret named HuggingFace API token
      # We use a SealedSecret in staging + prod for this
      #
      # Format:
      #   apiVersion: v1
      #   kind: Secret
      #   metadata:
      #     name: huggingface-token
      #     namespace: <namespace>
      #   data:
      #     token: YOUR_API_TOKEN
      secrets:
        - mountPath: '/root/.cache/token'
          name: 'token'
          subPath: 'token'
          readOnly: 'true'
          secretName: huggingface-token
          # "itemList" takes the place of "items"
          # This should avoid overlap with the built-in items() function
          itemList:
            - key: token
              path: token

    # Config for running SOMN job
    somn:
      image: "ianrinehart/somn:1.2.1"
      projectDirectory: '/tmp/somn_root/somn_scratch/IID-Models-2024'
      command: "cp ${JOB_INPUT_DIR}/example_request.csv ${SOMN_PROJECT_DIR}/scratch/test_request.csv && micromamba run -n base somn predict last latest asdf && cp -r ${SOMN_PROJECT_DIR}/outputs/asdf/*/* ${JOB_OUTPUT_DIR}"
      imagePullPolicy: "Always"
      securityContext:
        # TODO: mount/run as mambauser => 57439 causes permission errors
        # workaround for now is to run as root
        runAsUser: 0
        runAsGroup: 0
        #fsGroup: 57439
      volumes:
        - name: 'shared-storage'
          mountPath: '/uws/jobs/somn/JOB_ID/in'
          subPath: 'uws/jobs/somn/JOB_ID/in'
          claimName: 'mmli-clean-job-weights'
        - name: 'shared-storage'
          mountPath: '/uws/jobs/somn/JOB_ID/out'
          subPath: 'uws/jobs/somn/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'

    # Config for running NovoStoic job (subjob: OptStoic)
    novostoic-optstoic:
      image: "moleculemaker/novostoic"
      command: python ./novostoic-job.py optstoic 1> ${JOB_OUTPUT_DIR}/output.log 2> ${JOB_OUTPUT_DIR}/error.log; if [ "$?" -eq 0 ]; then touch ${JOB_OUTPUT_DIR}/success; else touch ${JOB_OUTPUT_DIR}/fail; fi
      imagePullPolicy: "Always"
      volumes:
        - name: 'shared-storage'
          mountPath: '/uws/jobs/novostoic-optstoic/JOB_ID/out'
          subPath: 'uws/jobs/novostoic-optstoic/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'
      resources:
        limits:
          cpu: "1"
          memory: "24Gi"
        requests:
          cpu: "1"
          memory: "12Gi"

    # Config for running NovoStoic job (subjob: NovoStoic Pathways Search)
    novostoic-pathways:
      image: "moleculemaker/novostoic"
      command: python ./novostoic-job.py pathways 1> ${JOB_OUTPUT_DIR}/output.log 2> ${JOB_OUTPUT_DIR}/error.log; if [ "$?" -eq 0 ]; then touch ${JOB_OUTPUT_DIR}/success; else touch ${JOB_OUTPUT_DIR}/fail; fi
      imagePullPolicy: "Always"
      volumes:
        - name: 'shared-storage'
          mountPath: 'uws/jobs/novostoic-pathways/JOB_ID/out'
          subPath: 'uws/jobs/novostoic-pathways/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'

    # Config for running NovoStoic job (subjob: dGPredictor)
    novostoic-dgpredictor:
      image: "moleculemaker/novostoic"
      command: python ./novostoic-job.py dgpredictor 1> ${JOB_OUTPUT_DIR}/output.log 2> ${JOB_OUTPUT_DIR}/error.log; if [ "$?" -eq 0 ]; then touch ${JOB_OUTPUT_DIR}/success; else touch ${JOB_OUTPUT_DIR}/fail; fi
      imagePullPolicy: "Always"
      volumes:
        - name: 'shared-storage'
          mountPath: '/uws/jobs/novostoic-dgpredictor/JOB_ID/out'
          subPath: 'uws/jobs/novostoic-dgpredictor/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'

    # Config for running NovoStoic job (subjob: EnzRank)
    novostoic-enzrank:
      image: "moleculemaker/novostoic"
      command: python ./novostoic-job.py enzrank 1> ${JOB_OUTPUT_DIR}/output.log 2> ${JOB_OUTPUT_DIR}/error.log; if [ "$?" -eq 0 ]; then touch ${JOB_OUTPUT_DIR}/success; else touch ${JOB_OUTPUT_DIR}/fail; fi
      imagePullPolicy: "Always"
      volumes:
        - name: 'shared-storage'
          mountPath: '/uws/jobs/novostoic-enzrank/JOB_ID/out'
          subPath: 'uws/jobs/novostoic-enzrank/JOB_ID/out'
          claimName: 'mmli-clean-job-weights'

    defaults:
      # Kubeconfig (credentials + cluster) used to run this job in Kubernetes
      kubeconfig: "/opt/kubeconfig"
      # Namespace where this job should run
      namespace: "mmli"

      # Example job image name + command combo
      image: 'perl:5.34.0'
      command: "perl -Mbignum=bpi -wle 'print bpi(2000)' > ${JOB_OUTPUT_DIR}/pi.out"

      ## Server working directory to store generated job data
      workingVolume:
        claimName: "mmli-clean-job-weights"
        mountPath: "/uws"
        subPath: "uws"
      ## Central data volumes to be mounted in job containers
      volumes: []

      ## Abort jobs after 3 days regardless of their behavior
      activeDeadlineSeconds: 259200
      ## Cleanup completed/failed jobs after 12 hours
      ttlSecondsAfterFinished: 43200
      ## Poll the log file for changes every `logFilePollingPeriod` seconds
      logFilePollingPeriod: 300

      # TODO: probably could adjust resource limits here
      resources:
        limits:
          cpu: "1"
          memory: "16Gi"
        requests:
          cpu: "1"
          memory: "12Gi"

  external:
    chemscraper:
      apiBaseUrl: "https://chemscraper.backend.staging.mmli1.ncsa.illinois.edu"
      frontendBaseUrl: "https://chemscraper.frontend.staging.mmli1.ncsa.illinois.edu"


