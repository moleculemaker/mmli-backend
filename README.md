# mmli-backend
Unified FastAPI based backend for ChemScraper, (CLEAN job-manager and Molli - future scope)

## â­ï¸ Recommended local development (Docker)

### (1/4) Create a `.env`
Create a `.env` from the `env.tpl` file in this repo. The default env is fine without modifications for testing. Change the passwords for production use.
```bash
cp .env.tpl .env
```

### (2/4) Setup a K8 cluster, here we use Minikube 
1. [Install Minikube](https://minikube.sigs.k8s.io/docs/start/?arch=%2Fmacos%2Farm64%2Fstable%2Fbinary+download).
2. Follow the instructions to set it up, e.g. `minikube start`
3. Ensure it's running: `minikube kubectl cluster-info`
```
Kubernetes control plane is running at https://192.168.49.2:8443
CoreDNS is running at https://192.168.49.2:8443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy
```

### (3/4) Run Docker Compose build

Edit the `docker-compose.yml` to expose your kube config. In our case, `minikube` requires 3 values: `ca.crt`, `client.crt`, `client.key`. 

Copy-paste this into the `docker-compose.yml`, under the `rest` container:

> âš ï¸ Note: I had problems with `${HOME}` and had to provide full absolute paths manually; e.g. replace `${HOME}` with `/home/username`. âš ï¸

```
rest:
    container_name: mmli-backend
    
    ...

    volumes:
        - ./app:/code/app
        - ./migrations:/code/migrations
        - ${HOME}/.kube/config:/opt/kubeconfig
        - ${HOME}/.minikube/ca.crt:/home/kastan/.minikube/ca.crt
        - ${HOME}/.minikube/profiles/minikube/client.crt:${HOME}/.minikube/profiles/minikube/client.crt
        - ${HOME}/.minikube/profiles/minikube/client.key:${HOME}/.minikube/profiles/minikube/client.key
        
```

Finally start the compose. Monitor for errors from `mmli-backend` in the logs.

```bash
docker compose up --build # optionally add -d for detached
```
This will run `MinIO` + `PostgreSQL` + the Python app `mmli-backend`.

**Test the service works:** Navigate to [`localhost:8080/docs`](localhost:8080/docs) and you should see the FastAPI Swagger docs.

### (4/4) Initialize the databse

Initialize the Postgres database, this creates the SQL tables.
```bash
docker compose exec -w /code rest alembic upgrade head

# You sould see the logs: 
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> d775ee615d7b, init
INFO  [alembic.runtime.migration] Running upgrade d775ee615d7b -> 88355d0f323b, added moleculecacheentry for caching molecules, modified job schema, added flaggedmolecule for saving flagged molecules
INFO  [alembic.runtime.migration] Running upgrade 88355d0f323b -> e8569ab45dd1, removed moleculecacheentry
INFO  [alembic.runtime.migration] Running upgrade e8569ab45dd1 -> 30b240622d34, add chemical identifier model and table
```
Finally, verify the tables are created: 

1. exec into the database container, running the `pgsql` command.
```bash
docker exec -it mmli-backend-postgresql psql -U postgres mmli
```
2. Run `\d` command to list tables. 
```bash
psql (15.8 (Debian 15.8-1.pgdg120+1))
Type "help" for help.

mmli=# \d 
                     List of relations
 Schema |            Name            |   Type   |  Owner
--------+----------------------------+----------+----------
 public | alembic_version            | table    | postgres
 public | chemical_identifier        | table    | postgres
 public | chemical_identifier_id_seq | sequence | postgres
 public | flaggedmolecule            | table    | postgres
 public | job                        | table    | postgres
(5 rows)
```
3. Check the jobs table `\d job`:
```bash
mmli=# \d job
                        Table "public.job"
    Column    |       Type        | Collation | Nullable | Default
--------------+-------------------+-----------+----------+---------
 job_info     | character varying |           |          |
 email        | character varying |           |          |
 job_id       | character varying |           | not null |
 run_id       | character varying |           |          |
 phase        | character varying |           | not null |
 type         | character varying |           | not null |
 image        | character varying |           |          |
 command      | character varying |           |          |
 time_created | integer           |           | not null |
 time_start   | integer           |           | not null |
 time_end     | integer           |           | not null |
 deleted      | integer           |           | not null |
 user_agent   | character varying |           | not null |
Indexes:
    "job_id_pk" PRIMARY KEY, btree (job_id)
Referenced by:
    TABLE "flaggedmolecule" CONSTRAINT "flaggedmolecule_job_id_fkey" FOREIGN KEY (job_id) REFERENCES job(job_id)
```

ðŸŽ‰ All done! ðŸŽ‰ Check the Swagger docs for important commands on [`localhost:8080/docs`](localhost:8080/docs).

## Local development Setup (without Docker, not recommended)

### (1/4) Configure Environment
Create a `.env` from the `env.tpl` file in this repo. The default env is fine without modifications for testing. Change the passwords for production use.
```bash
cp .env.tpl .env
```

Setting `DEBUG=true` will enable automatically reload the app when the Python source code changes

### (2/4) Install dependencies
Or, you can use Python + pip if you have them installed locally

To install Dependencies:
```bash
# create a new virtual environment, e.g. for conda `conda create -n mmli-backend python=3.10 -y`
# conda activate mmli-backend
pip install -r requirements.txt
```

This will only run the Python app.

âš ï¸ You must run `MinIO` and `PostgreSQL` yourself. Set their credentials in the `.env` file.

### (3/3) Initialize the databse

Initialize the Postgres database, this initializes the SQL tables.
```bash
alembic upgrade head
```
This will apply the "init" migration and create the needed database tables:
```bash
INFO  [alembic.runtime.migration] Context impl PostgresqlImpl.
INFO  [alembic.runtime.migration] Will assume transactional DDL.
INFO  [alembic.runtime.migration] Running upgrade  -> d775ee615d7b, init
```

Finally, verify the tables are created: 

1. Run the `pgsql` command.
```bash
psql mmli
```
2. Run `\d` command to list tables. 
```bash
psql (15.8 (Debian 15.8-1.pgdg120+1))
Type "help" for help.

mmli=# \d 
                     List of relations
 Schema |            Name            |   Type   |  Owner
--------+----------------------------+----------+----------
 public | alembic_version            | table    | postgres
 public | chemical_identifier        | table    | postgres
 public | chemical_identifier_id_seq | sequence | postgres
 public | flaggedmolecule            | table    | postgres
 public | job                        | table    | postgres
(5 rows)
```
3. Check the jobs table `\d jobs`:
```bash
mmli=# \d job
                        Table "public.job"
    Column    |       Type        | Collation | Nullable | Default
--------------+-------------------+-----------+----------+---------
 job_info     | character varying |           |          |
 email        | character varying |           |          |
 job_id       | character varying |           | not null |
 run_id       | character varying |           |          |
 phase        | character varying |           | not null |
 type         | character varying |           | not null |
 image        | character varying |           |          |
 command      | character varying |           |          |
 time_created | integer           |           | not null |
 time_start   | integer           |           | not null |
 time_end     | integer           |           | not null |
 deleted      | integer           |           | not null |
 user_agent   | character varying |           | not null |
Indexes:
    "job_id_pk" PRIMARY KEY, btree (job_id)
Referenced by:
    TABLE "flaggedmolecule" CONSTRAINT "flaggedmolecule_job_id_fkey" FOREIGN KEY (job_id) REFERENCES job(job_id)
```

ðŸŽ‰ All done! ðŸŽ‰ Check the Swagger docs for important commands on [`localhost:8080/docs`](localhost:8080/docs).

# Database Migrations
Any time that you add, modify, or remove anything in the Job or JobBase classes, this will affect the database schema.

Migrations are handled using [Alembic](https://alembic.sqlalchemy.org/en/latest/)

You can use Alembic to automatically generate a script that will migrate the database to a new schema version.

See the [migrations](migrations/README.md) README for more info
